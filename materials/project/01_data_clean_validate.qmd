---
title: "01_Data Clean and Validate"
description: Scheduled document to clean and validate data
editor_options: 
  chunk_output_type: console
execute: 
  eval: false
---
 
# Load packages
```{r}
#| label: Load packages

library(tidyverse)
library(janitor)
library(DBI)
library(odbc)
library(RPostgres)
library(pins)
library(pointblank)
library(blastula)
library(glue)

```

# Pull data from Database

```{r}
#| label: DB Connection

con <- dbConnect(RPostgres::Postgres(), 
                 host = Sys.getenv("DB_HOST"), 
                 port = "5432", 
                 dbname = "r_workshop", 
                 user = Sys.getenv("DB_USER"), 
                 password = Sys.getenv("DB_PASSWORD"))


```

```{r}
#| label: Pull raw data

# DATASET 1: Food inspections data, with some time logging for reference
inspections_raw <- 
  tbl(con, "inspections_raw") |> 
  collect() |> 
  # convert inspection_date to date format
  mutate(inspection_date = lubridate::mdy(inspection_date)) 


# DATASET 2: Business data
bus_data_raw <- tbl(con, "bus_data_raw") |>
  # Filter only relevant facility types. Do this before we collect into local memory
  filter(license_description %in% c(
                                    "RETAIL FOOD - SEASONAL LAKEFRONT FOOD ESTABLISHMENT",
                                    "RETAIL FOOD ESTABLISHMENT",
                                    "WRIGLEY FIELD")) |> 
  collect() |> 
  mutate(license_term_expiration_date = lubridate::mdy(license_term_expiration_date)) |> 
  # Add column to determine if license is still valid
  mutate(license_valid = case_when(license_term_expiration_date > lubridate::today() ~ "TRUE", .default = "FALSE")) 

```

# Perform inspections data filtering and cleaning.

```{r}
#| label: Thin out inspection data pre-validation

inspections_step1 <- 
  inspections_raw |> 
  # Clean facility_type
  mutate(facility_type = case_when(
    grepl("RE?STA?U?R?A?N?T?", `facility_type`) ~ "RESTAURANT",
    grepl("BA?KE?R?Y?", `facility_type`) ~ "BAKERY",
    grepl("COFFEE *SHOP", `facility_type`) ~ "COFFEE SHOP", 
    grepl("WRIGLEY", `facility_type`) ~ "WRIGLEY FIELD ROOFTOP",
    .default = paste("OTHER")
    )) |> 
  
  # filter out inspections not at a restaurant, bakery, coffee shop, or Wrigley
  filter(facility_type != "OTHER") |> 
  
   # Filter for only Pass, Fail, Pass with conditions
  filter(results %in% c("PASS", "FAIL", "PASS W/ CONDITIONS")) |>
  
  # Convert "Pass w/ Conditions" to Fail (since it is a failure, but was corrected
  #  before the food inspector left)
  mutate(results = if_else(results == "PASS W/ CONDITIONS", "FAIL", results)) |> 
  
  # Refactor risk
  mutate(risk = case_when(
    risk == "RISK 1 (HIGH)" ~ 1,
    risk == "RISK 2 (MEDIUM)" ~ 2,
    risk == "RISK 3 (LOW)" ~ 3
  ))


#Now let's also join in the reference business data table so we have a "source of truth" DBA name to check against.
# inspections_step2 <- 
#   inspections_step1 |> 
#   left_join(select(bus_data_ref, license_number, doing_business_as_name), by=join_by(license_number)) |>
#   rename(ref_dba_name = doing_business_as_name) 

# Finally, add a column with the Jaro ("jw") string distance to help us determine how similar or dissimilar the inspectors' inputted dba name is to the reference. A distance of 0 indicates identical; a 1 indicates completely dissimilar
# inspections_processed <- tidystringdist::tidy_stringdist(inspections_step2,v1=dba_name, v2=ref_dba_name, method="jw") 

inspections_clean <- inspections_step1

```

# Inspections data validation
Perform data validation. The first validation just confirms the overall size and format of the data frame. If the validation fails here, a warning is thrown and the validation will not proceed.
```{r}
#| label: data frame size and format validation

# Define a column schema so we can check inputted data is as expected
# Fun fact, also use .tbl argument in col_schema to compare the dataframe to an ideal table.
# troubleshooting, if this fails, look at the x_list$col_types and $col_names to see the discrepancy
schema_inspections <- col_schema(inspection_id = "numeric",
                               dba_name = "character",
                               aka_name = "character",
                               license_number = "numeric",
                               facility_type = "character",
                               risk = "numeric",
                               address = "character",
                               city = "character",
                               state = "character",
                               zip = "numeric",
                               inspection_date = "Date",
                               inspection_type = "character",
                               results = "character",
                               violations = "character",
                               latitude = "numeric",
                               longitude = "numeric",
                               location = "character"
                               )


#### VALIDATION 1: Data set integrity validations. All of these trigger a warning under fail conditions.
agent_df_integrity <- 
  create_agent(inspections_clean, label = "Inital validation of the inspections data set to confirm overall schema and size. If there are issues with this validation, further processing stops and an alert is triggered.") |> 
  # verify column schema 
  # troubleshooting, if this fails, look at the x_list$col_types and $col_names to see the discrepancy
  col_schema_match(schema_inspections, 
                   label = "Is the column schema as expected?", 
                   actions = action_levels(warn_at = 1)) |> 
  #Check that expected columns exist. We make a table in the preconditions using a table transform that is made up of the column names of our inspections table. Then compare those values to the set of schema_inspection names.
  col_vals_in_set(columns = value, 
                  set = names(schema_inspections), 
                  preconditions = ~. %>% tt_tbl_colnames, 
                  label = "Are the expected columns in the data set?", 
                  actions = action_levels(warn_at = 0.01) ) |> 
  # verify there are A LOT of rows of data to be sure import didn't mess up. 
  col_vals_gte(columns = n, 
               value = 100000L, # an arbitrary high-ish number
               preconditions = ~. %>% tally,
               label = "Are there more than 100k rows in the data?", 
               actions = action_levels(warn_at = 1)) |>
  interrogate()
agent_df_integrity
alert_me <- !(all_passed(agent_df_integrity))


#Send an email alert if the data frame validation fails

if (alert_me == TRUE){
  render_connect_email(input = "email-01_data_integrity_alert.Rmd") |> 
    attach_connect_email(subject = "⚠️Inspections Project: Validation of Inspections dataset found integrity issue")
} 

```

# Data validation
As long as the the validation on Data Frame integrity passes, the following additional validations will run
```{r}
#| label: Data integrity validation
#| eval: !expr all_passed(agent_df_integrity)

#### VALIDATION 2: Data integrity validations. Failing rows from this validation will be stripped out. We can monitor these over time if we create a multi_agent too.
agent_main <-  
  create_agent(inspections_clean, label = "Validation of inspections data") |> 
  # No null values
  col_vals_not_null(columns = inspection_id) |> 
  col_vals_not_null(columns = dba_name) |> 
  col_vals_not_null(columns = address) |> 
  col_vals_not_null(columns = inspection_date) |> 
  col_vals_not_null(columns = inspection_type) |> 
  col_vals_not_null(columns = results) |> 
  # verify Inspection ID is unique
  rows_distinct(columns = vars(inspection_id), 
                label = "Is the Inspection ID unique?", 
                actions = action_levels(warn_at = 0.001)) |> 
  # verify inspection ID is valid
  col_vals_between(columns = inspection_id, 1000, 99999999, 
                   label = "Is the Inspection ID a valid entry?") |>  # verify inspection ID is valid
  # verify license number is valid
  col_vals_between(columns = license_number, 1, 99999999, 
                   label = "Is the License Number a valid entry?") |>
  # verify lat and long bounds (set na_pass = TRUE to ignore NAs)
  col_vals_between(columns = latitude, left = 41.5001, right = 42.3772, na_pass = TRUE) |> 
  col_vals_between(columns = longitude, left = -88.2959, right = -87.316, na_pass = TRUE) |> 
  # verify w col_vals_within_spec for postal_code / aka zip
  col_vals_within_spec(columns = zip, spec = "postal[USA]", na_pass = TRUE) |> 


  # Is the DBA inconsistent with that listed on the Business License?
  # col_vals_lte(columns = jw, 
  #              value = 0.34, 
  #              label = "Dissimilarity measure between reported DBA Name and licensed DBA Name") |> 
  interrogate() 

agent_main

```

# Sunder the data to remove failed rows
```{r}
#| label: Sunder data

inspections_validated <- get_sundered_data(agent_main, type = "pass")

```



# Data transformations

Make and pin a reference table of DBA Names using the most current business license number to act as the list of possible choices to input into the model.  These DBA Names can also act as the "source of truth" for what the correct DBA Name should be for a given license number.
```{r}
#| label: Reference table - Restaurant choices to submit to model 



restaurants_ref <- 
  bus_data_raw |> 
  # Filter out if license is expired
  filter(license_valid == TRUE) |> 
  group_by(license_number) |> 
  arrange(desc(license_term_expiration_date)) |> 
  # Keep only the most recent entry for a particular license number
  slice(1) |> 
  select(-business_activity) |> 
  ungroup()

board <- board_connect()
board |> pin_write(restaurants_ref, 
                   description = "Reference df with the list of restaurants that 
                   can be submitted to the model. 
                   From business data only, filtered by license_description to be 
                   a retail food establishment or wrigley field ⚾, thinned to only 
                   keep facilities with an active license, 
                   and only the most recent license")


```
  




```{r}
#| label: transform data

inspections_transform <- 
  inspections_validated |> 
  # Extract violations (v_list) and total violation numbers (v_num)
  rowwise() |> 
  mutate(v_list = case_when(
    is.na(violations) ~ NA,
    !is.na(violations) ~ str_extract_all(violations, 
                                         "(^\\d{1,2}|\\|\\s*\\d{1,2})"))) |> 
  mutate(v_list = case_when(
    is.null(v_list) ~ NA,
    !is.null(v_list) ~ list(str_replace_all(v_list, "\\|\\s*", "")))) |> 
  mutate(v_num = length(v_list)) |> 

  # Detect number of critical/serious violations (#'s 1 to 29)
  mutate(v_num_cs = sum(1:29 %in% unlist(v_list))) |> 

  # Calculate cumsum violation number
  group_by(license_number) |> 
  arrange(inspection_date) |> 
  mutate(v_total = sum(v_num)) |> 
  mutate(v_cumsum = cumsum(v_num)) |> 
  mutate(v_cumsum_cs = cumsum(v_num_cs)) |> 
  ungroup(license_number)  
```


Load data into database
```{r}
#| label: Write processed data to database

# write processed inspections data
dbWriteTable(con, "inspections_processed", inspections_processed, overwrite = TRUE)
print("Processed inspection data updated 🎉")


# write business name reference table
dbWriteTable(con, "bus_data_ref", bus_data_ref, overwrite = TRUE)
print("Reference business name data updated 🎉")


# insp_db <- tbl(con, "inspections_raw")
# insp_db |> tally()
# 
# bus_db <- tbl(con, "bus_data_raw")
# bus_db |>  tally()


dbDisconnect(con)
```


Let's also pin our processed data and reference business data
```{r}
#| label: pin the data

board <- board_connect()
user_name <- "katie.masiello"
board |> pin_write(inspections_processed,name = paste0(user_name,"/inspections_processed"), type="arrow")

board |> pin_write(bus_data_ref,name = paste0(user_name,"/bus_data_ref"), type="arrow")


```

# Logging information
```{r}
#| label: logging
#| results: asis

glue("Report run {blastula::add_readable_time()}")

if(alert_me == TRUE){
  glue("Validation of inspection data set integrity failed. An email alert was generated, and is shown below. {email_alert$html_html}")
} else {
  glue("Inspection data was validated and sundered. Rows that failed validation were removed.")
}

```
