---
title: 02_model_creation
---

## Set up Environment

```{r}
#| label: load-packages
#| output: false
#| warning: false
#| message: false

library(tidymodels)
library(tidyverse)
library(embed)

tidymodels_prefer()
```

## Read in Data

```{r}
#| label: read-data
#| cache: true

# For testing purposes, I'll only read in 20,000 rows
inspections_raw <- readr::read_csv("https://data.cityofchicago.org/api/views/4ijn-s7e5/rows.csv", n_max = 20000, show_col_types = FALSE) |> 
  mutate(Zip = as.character(Zip))
```

## Clean Data

```{r}
inspections_clean <- inspections_raw |> 
  # Filter for only certain facility types
  filter(`Facility Type` %in% c("Restaurant", "Grocery Store", "School", "Bakery")) |> 
  
  # Filter for only Pass, Fail, Pass with conditions
  filter(Results %in% c("Pass", "Fail", "Pass w/ Conditions")) |>
  
  # Convert "Pass w/ Conditions" to Fail (since it is a failure, but was corrected
  #  before the food inspector left)
  mutate(Results = if_else(Results == "Pass w/ Conditions", "Fail", Results)) |> 
  
  # Filter for Chicago IL
  filter(State == "IL") |> 
  filter(City %in% c("CHICAGO")) |> 
  
  # Remove non-relevant columns
  select(-`AKA Name`, -Location, -Address) |> 
  
  # Extract violations (v_list) and total violation numbers (v_num)
  rowwise() |> 
  mutate(v_list = case_when(
    is.na(Violations) ~ NA,
    !is.na(Violations) ~ str_extract_all(Violations, 
                                         "(^\\d{1,2}|\\|\\s*\\d{1,2})"))) |> 
  mutate(v_list = case_when(
    is.null(v_list) ~ NA,
    !is.null(v_list) ~ list(str_replace_all(v_list, "\\|\\s*", "")))) |> 
  mutate(v_num = length(v_list)) |> 

  # Detect number of critical/serious violations (#'s 1 to 29)
  mutate(v_num_cs = sum(1:29 %in% unlist(v_list))) |> 

  # Calculate cumsum violation number
  group_by(`License #`) |> 
  arrange(`Inspection Date`) |> 
  mutate(v_total = sum(v_num)) |> 
  mutate(v_cumsum = cumsum(v_num)) |> 
  mutate(v_cumsum_cs = cumsum(v_num_cs)) |> 
  ungroup(`License #`) |> 
  
  # Refactor risk
  mutate(Risk = case_when(
    Risk == "Risk 1 (High)" ~ 1,
    Risk == "Risk 2 (Medium)" ~ 2,
    Risk == "Risk 3 (Low)" ~ 3
  )) |> 
  
  # Filter for just (potential) predictors
  select(Results, `DBA Name`, `License #`, `Facility Type`, `Risk`, `Zip`, v_cumsum, v_cumsum_cs)
```

## Split Data

```{r}
#| label: split-data

set.seed(1234)

# Define split
inspections_split <- initial_split(inspections_clean, prop = 0.75)
inspections_split

# Create taining and testing datasets
inspections_train <- training(inspections_split)
inspections_test <- testing(inspections_split)
```

## Create Model Recipe

```{r}
#| label: create-recipe

rec <- recipe(Results ~ `Facility Type` + Risk + Zip + v_cumsum + v_cumsum_cs, 
              data = inspections_train) |> 
  # Convert facility type to binary columns
  step_dummy(`Facility Type`) |> 
  # Convert zip (which has many levels) to a set of scores
  #  derived from a glm model that estimates the effect
  #  of each Zip code on the outcome. Likelihood encoding.
  step_lencode_glm(Zip, outcome = vars(Results))

rec
```

## Build xgboost model

We first need to define some specifications for the xgboost model. There are lots of them, and we'll insert the `tune()` placeholder for now.

```{r}
#| label: model-specs

# xgboost model specifications
xgb_spec <- parsnip::boost_tree(
  mode = "classification",
  trees = 1000,
  tree_depth = tune(),
  min_n = tune(),
  loss_reduction = tune(),
  sample_size = tune(),
  mtry = tune(),
  learn_rate = tune()
) |> 
  set_engine("xgboost")

xgb_spec
```

We now can use the `dials` package to create parameter grids:

```{r}
xgb_grid <- grid_latin_hypercube(
  tree_depth(),
  min_n(),
  loss_reduction(),
  sample_size = sample_prop(),
  finalize(mtry(), inspections_train),
  learn_rate(),
  size = 30
)

xgb_grid
```

Now we can create a workflow with these specifications and our recipe:

```{r}
xgb_wf <- workflow() |> 
  add_recipe(rec) |> 
  add_model(xgb_spec)

xgb_wf
```

Create cross-validation resamples for tuning our model:

```{r}
set.seed(1234)
inspections_folds <- vfold_cv(inspections_train, strata = Results)

inspections_folds
```

Tune the model:

```{r}
doParallel::registerDoParallel()

set.seed(1234)
xgb_res <- tune_grid(
  xgb_wf,
  resamples = inspections_folds,
  grid = xgb_grid,
  control = control_grid(save_pred = TRUE)
)

xgb_res
```

```{r}
collect_metrics(xgb_res)

xgb_res %>%
  collect_metrics() %>%
  filter(.metric == "roc_auc") %>%
  select(mean, mtry:sample_size) %>%
  pivot_longer(mtry:sample_size,
               values_to = "value",
               names_to = "parameter"
  ) %>%
  ggplot(aes(value, mean, color = parameter)) +
  geom_point(alpha = 0.8, show.legend = FALSE) +
  facet_wrap(~parameter, scales = "free_x") +
  labs(x = NULL, y = "AUC")
```

```{r}
show_best(xgb_res, "roc_auc")
```
