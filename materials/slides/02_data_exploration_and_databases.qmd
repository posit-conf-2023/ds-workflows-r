---
format:
  positconfslides-revealjs: 
    chalkboard: true
    slide-number: c/t
    footer: "[https://posit-conf-2023.github.io/ds-workflows-r/](https://posit-conf-2023.github.io/ds-workflows-r/)"
    code-copy: true
    center-title-slide: false
    code-link: true
    code-overflow: wrap
    code-annotations: hover
    highlight-style: a11y
    width: "1600"
    height: "900"
    filters:
      - positconfslides
execute: 
  eval: true
  echo: true
---

## Data Exploration and {.toc2-light}
<h2>Working with Databases</h2>
![](https://github.com/rstudio/pointblank/raw/main/man/figures/logo.svg){.absolute top="200" left="50" width="260"} ![](slide_resources/db.png){.absolute top="200" left="310" width="260"}

## Section Agenda {.brackets-light}


-   Ad-hoc data exploration
-   Writing production data to a database 
-   Automating the process 



## Project overview


![](slide_resources/workflow_diagram.jpg){fig-align="center"}




## What is this Data?


Our first introduction to `pointblank`



:::{.fragment}

::: columns
::: {.column width="15%"}
![](https://github.com/rstudio/pointblank/raw/main/man/figures/logo.svg){style="padding-right: 15px;"}
:::

::: {.column width="75%"}
<br>`pointblank` provides data quality assessment and metadata reporting for data frames and database tables. <https://github.com/rstudio/pointblank>
:::
:::

:::

:::{.fragment}
🧰 The `pointblank::scan_data()` function provides a HTML report of the input data to help you understand your data. 
:::

## Sample data scan

```r
pointblank::scan_data(palmerpenguins::penguins)
```
<br>


<iframe src="slide_resources/scan_penguins.html" width=100% height="650"></iframe>
 
## 

:::{.center}
<h2> <br>**Activity Time!**</h2>
:::

:::{.callout-note icon=false}
## Activity
👉 Open the file `materials/activities/activity-01_raw_data_exploration.qmd`

Activity objective: explore our Chicago Food Inspections data to get familiar with our data
:::



```{r}
#| echo: false
countdown::countdown(minutes=7,seconds=0, font_size = "4em")
```



 
## Where should I put the data?

:::{.fragment .middle .r-fit-text}
📣 Production data belongs in a database.
:::

## Database Connection Essentials^[the single slide edition]

:::{.incremental .smaller}
- Database connections have 2 parts: 
  <br>[An ODBC^[📣 use ODBC drivers whenever possible. Avoid JDBC unless you like managing Java installations] driver (typically installed on your system and not R-specific)]{.teal}
  <br>[A means to interact with the driver (e.g., R package)]{.teal}
- `odbc` is an R package that provides a generic interface to the ODBC driver installed on your system. *This is your Swiss Army Knife for database connections* and integrates with the "Connections" Pane in the RStudio IDE
- 🧰 `RPostgres`, `RMariaDB`, `RSQLite`, and `bigrquery` are database-specific R packages that implement the drivers themselves. *They combine the two parts of a connection into one.* In many cases, they are more performant (especially in writing data) and may have more translations available for query types.
- 💡These will make the same connection
  ```r
  con <- DBI::dbConnect(RPostgres::postgres(), ...)
  con <- DBI::dbConnect(odbc::odbc(), driver = “Postgres”, ...)
  ```
:::

## Interacting with Databases^[the single slide edition]

:::{.incremental}

- What tables are in a database? `DBI::dbListTables(con)`
- Write to database with `DBI::dbWriteTable(con, "name", df)`
- Use `dplyr` to interact with the database table in the same manner you would a local data frame
  ```{.r code-line-numbers=false}
  df <- dplyr::tbl(con, "table-name")
  df |> filter(...) |> mutate(...) |> group_by(...) |> summarise(...)
  
  ```
- 📣 Do as much work as possible in the database. Use `dplyr::collect()` to bring the table into memory. Do this as late as possible to save time and resources

  ```{.r code-line-numbers=false}
  df |> ... |> collect()
  
  ```

:::

## More on databases {.content-light}

:::{.callout-tip icon=false}
## {{< bi sign-turn-right-fill color=orange >}} Best practices in working with databases

<https://solutions.posit.co/connections/db/> 


Specific resources:

::::{columns}

:::{.column width=40%}
- [Connect to a database](https://solutions.posit.co/connections/db/getting-started/connect-to-database/)
- [Query a database table](https://solutions.posit.co/connections/db/getting-started/database-queries/)
:::

:::{.column width=60%}

- [Securing credentials](https://solutions.posit.co/connections/db/best-practices/managing-credentials/)
- [Making scripts portable](https://solutions.posit.co/connections/db/best-practices/portable-code/)
:::
::::

:::


## How do I automate this process?

:::{.fragment}
🧰 Deploy and schedule your notebook on Posit Connect

![](slide_resources/scheduling.png){height="700" fig-align="center"}

:::



## 

:::{.center}
<h2> <br>**Activity Time!**</h2>
:::

:::{.callout-note icon=false}



## Activity
👉 Open the file `materials/activities/activity-02_publish_and_schedule_data_pull.Rmd`

Activity objective: Write production data to database, then deploy and schedule this work on Posit Connect so it runs automatically. 

:::



```{r}
#| echo: false
countdown::countdown(minutes=10,seconds=0)
```



## Deployment Methods to Posit Connect

:::{.fragment}

1. Push-button ![](slide_resources/publishIcon_2x.png){height="50" style="vertical-align:middle"} 
2. Git-backed {{< fa brands git-alt >}}
3. Programmatic {{< fa gears >}}

:::
:::{.fragment}

📣 Push-button is good for rapid prototyping. Beyond that, you really should be using [**git-backed or programmatic deployment via CI/CD pipeline**]{.fuchsia} to keep your code in sync with your deployment. 

<!-- TODO: find a place to have a git back deploy activity -->
:::



## Review

![](slide_resources/workflow_diagram.jpg){fig-align="center"}

