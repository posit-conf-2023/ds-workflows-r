---
title: "activity-00_Raw Data Exploration"
description: "Conduct ad hoc exploration of the data, first exposure to `pointblank`"
toc: true
toc-depth: 4
editor_options: 
  chunk_output_type: console
---

This workshop will use data from the City of Chicago Open Data Portal: <https://data.cityofchicago.org>. The following datasets will be used:

1.  üçïFood inspections: <https://data.cityofchicago.org/Health-Human-Services/Food-Inspections/4ijn-s7e5>
2.  üìíBusiness license data: <https://data.cityofchicago.org/Community-Economic-Development/Business-Licenses/r5kz-chrr>

## Setup

Load required packages for importing and exploring the data

```{r}
#| label: Load packages

library(tidyverse)
library(pointblank)

```

## Activity 1 - Read data
üîÑ Task

- Explore the two data sources
- Load the data into tibbles

‚úÖ Solution

The City of Chicago data portal provides access to their datasets via the Socrata Open Data (SODA) API. Consulting the documentation provides us with some examples of how to use SODA: <https://dev.socrata.com/foundry/data.cityofchicago.org/4ijn-s7e5>.

We will query the SODA API directly and download the full dataset as a `.csv` using `readr::read_csv()`.^[There is a R package called `RSocrata` to interact with SODA, however, in our initial testing, the column schemas were better-preserved using `readr` as opposed to using the `RSocrata` package]



### Download data from City of Chicago

#### DATASET 1: Food inspections data

```{r}
#| label: Pull raw inspections data

inspections_raw <- 
  readr::read_csv("https://data.cityofchicago.org/api/views/4ijn-s7e5/rows.csv") 
```



#### DATASET 2: Business data

```{r}
#| label: Pull raw business data

bus_data_raw <- 
  readr::read_csv("https://data.cityofchicago.org/api/views/r5kz-chrr/rows.csv") 
```

## Activity 2 - Scan the data

üîÑ Task

Use the `pointblank` package to gather basic information about the Food Inspections data so we can

- Understand what the data is
- Get a sense for how much cleaning is required
- Plan our approach for data validation


‚úÖ Solution

::: callout-tip
## The `pointblank` package

::: columns
::: {.column width="20%"}
![](https://github.com/rstudio/pointblank/raw/main/man/figures/logo.svg){style="padding-right: 15px;"}
:::

::: {.column width="75%"}
<br> `pointblank` provides data quality assessment and metadata reporting for data frames and database tables. 

**Reference**: <https://github.com/rstudio/pointblank>
:::
:::
:::

The `pointblank::scan_data()` function provides a HTML report of the input data to help you understand your data. It contains 6 sections:

-   **Overview (O)**: Table dimensions, duplicate row counts, column types, and reproducibility information
-   **Variables (V)**: A summary for each table variable and further statistics and summaries depending on the variable type
-   **Interactions (I)**: A matrix plot that shows interactions between variables
-   **Correlations (C)**: A set of correlation matrix plots for numerical variables
-   **Missing Values (M)**: A summary figure that shows the degree of missingness across variables
-   **Sample (S)**: A table that provides the head and tail rows of the dataset

The scan can take a little while to run on a large dataset, but you can also omit sections that are not needed. 

First try it out on a small data frame, such as `penguins` from the `palmerpenguins` package:

```{r}
#| label: Data scan on mtcars

pointblank::scan_data(palmerpenguins::penguins) 

```

Our Food Inspection data is much larger than mtcars so to save time, and because these sections aren't relevant for this data, we omit "Correlations" and "Interactions."

```{r}
#| label: Data scan on inspections_raw

scan <- pointblank::scan_data(inspections_raw, sections = "OVMS")
scan

```

## Activity 3 - Explore the data scan

üîÑ Task

Explore the data scan and share your observations in slido.  
<!-- TODO: ADD SLIDO INFO -->

1.  What is the most common value for `DBA NAME` and `AKA Name` (hint: Toggle details)
2.  Explore the `Facility Type`. Does the number of distinct values surprise you?
3.  What can we the Missing Values diagram tell us about potential data quality issues?

How will this inform our data cleaning and validation?  

‚úÖ Solution

When we inspect the Facility Type, we see there is a lot of variation in how the inspector recorded this data. It certainly doesn't align with the stated possible values in the data documentation.

```{r}
#| label: Explore variation in the Facility Type

# What variations are there for "Restaurant" 
inspections_raw |> 
  filter(grepl("REST", `Facility Type`, ignore.case = TRUE)) |> 
  group_by(`Facility Type`) |> 
  tally() |> 
  arrange(desc(n)) |> print(n=20)

# Or Grocery Store?
inspections_raw |> 
  filter(grepl("GROC", `Facility Type`, ignore.case = TRUE)) |> 
  group_by(`Facility Type`) |> 
  tally() |> 
  arrange(desc(n)) |> print(n=20)

# Bakery
inspections_raw |> 
  filter(grepl("BAKERY", `Facility Type`, ignore.case = TRUE)) |>
  group_by(`Facility Type`) |>
  tally() |> 
  arrange(desc(n)) |> print(n=20)

# Coffee Shop
inspections_raw |> 
  filter(grepl("COFFEE", `Facility Type`, ignore.case = TRUE)) |>
  group_by(`Facility Type`) |>
  tally() |> 
  arrange(desc(n)) |> print(n=20)
```

Use this space if you'd like to do your own exploration:
```{r}
#| label: My scratchpad



```


Some conclusions from exploration: 

- We've got some very messy data, particularly in `FACILITY TYPE`
- We are going to want the `FACILITY TYPE` to be as clean as possible so we can filter out the establishments we don't care about for this analysis (e.g., hotels, caterers, etc.). A grep search seems sufficient for identifying types of interest.
- Share your own observations in Slido

## Activity 4 - Write raw data to database

üîÑ Task

- Create a database connection using the DSN defined for you by your IT Admin (Workshop Instructors)
- Write the raw data, `inspections_raw` and `bus_data_raw` to the database with your name appended to the table name, i.e., 
  - `inspections_raw_masiello` and `bus_data_raw_masiello`
  
‚úÖ Solution

<!-- TODO: configure a DSN For the database. Can this work with the `RPostgres` package? -->
```{r}
#| label: Connect to the Postgres database

con <- dbConnect(RPostgres::Postgres(), 
                 host = Sys.getenv("CONF23_DB_HOST"), 
                 port = "5432", 
                 dbname = "conf23_r", 
                 user = Sys.getenv("CONF23_DB_USER"), 
                 password = Sys.getenv("CONF23_DB_PASSWORD"))

```

```{r}
#| label: Write raw data to database

my_name <- Sys.getenv("USER")

# We use `overwrite = TRUE` rather than appending to an existing table
dbWriteTable(con, paste0("inspections_raw_",my_name), inspections_raw, overwrite = TRUE)

dbWriteTable(con, paste0("bus_data_raw_",my_name), bus_data_raw, overwrite = TRUE)


```


At this point, we have a good sense of the data, we've moved it to a database, and can move on from ad hoc exploration into a repeatable workflow üéâ  

