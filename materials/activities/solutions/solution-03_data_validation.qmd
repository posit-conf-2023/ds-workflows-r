---
title: "activity-03_data_validation.qmd"
description: "This notebook performs data validation using `pointblank`"
toc: true
toc-depth: 4
editor: visual
editor_options: 
  markdown:
    wrap: 72
    canonical: true
  chunk_output_type: console
execute: 
  eval: false
---

## Goals

The goals of this activity are to:

-   Use the `pointblank` package to perform data validations

-   Define thresholds in data validation to be used for alerting

✏️ There will be placeholders (`____`) in the code cells below that you
will need to fill in!

## Setup

### Load required packages for data validation

```{r}
#| label: Load packages

library(tidyverse)
library(pointblank)
library(pins)

```

### Read data from pin

We are going to start with a data set called `inspections_filtered`.
This data is an extract from the original `inspections_raw` data set,
which has been filtered to only include records of interest.
Specifically, it only includes inspection records that were marked as
"Pass," "Fail," or "Pass w/ Conditions" from the following Facility
Types:

\- Restaurants

\- Grocery Stores

\- Bakeries

\- Coffee Shops

\- Wrigley Field Rooftop (because that sounds pretty fun)

This data has been saved for you as a pin.

📌 We will talk more about pins during the Modeling section of this
workshop!

```{r}
#| label: read data from pin

# Define the board (i.e., virtual corkboard). Do not add any arguments to this code; run as-is.
board <- pins::board_connect()

# Read the existing pin with the data we'll use for this exercise.
inspections_filtered <- board |> 
  pins::pin_read("katie.masiello/inspections_filtered")

inspections_filtered

```

## Task 1 - Data validation on `inspections_filtered`

🔄 Task

Use the `pointblank` package to validate our `inspections_filtered`
dataset

-   create an agent
-   define validations
-   interrogate the table

The first step in the `pointblank` workflow is to create an **agent.**

```{r}
#| label: create agent for inspections_filtered

agent <- pointblank::create_agent(inspections_filtered)
agent
```

On its own, the agent is not very informative. It's waiting for
validations to be defined and an interrogation action to be performed.

Now we define our **data validation functions**. A few have been started
for you as examples. It's up to you to fill in the suggested
validations. Refer to the package documentation for the validation
function reference:
<https://rstudio.github.io/pointblank/reference/index.html#validation-expectation-and-test-functions>

```{r}
#| label: define validations for inspections_filtered

agent <- create_agent(inspections_filtered) |> 
  # verify license number is not NULL or NA
  col_vals_not_null(columns = license_number) |> 
  # verify license number is greater than 2000
  col_vals_gt(columns = license_number, 2000) |> 
  # verify inspection date is valid
  col_vals_lte(columns = inspection_date, today(),
               label = "Is inspection date in the past?") |> 
  # Now add the following:
  # verify that address, latitude, and/or longitude are not null/NA
  # (hint: use `vars(x,y,z)` to apply the validation to multiple columns)
  col_vals_not_null(vars(address, latitude, longitude)) |> 
  # verify that the values in inspection ID are distinct 
  rows_distinct(vars(inspection_id), 
                label = "Is the Inspection ID unique?") |> 
  # verify the latitude is within the bounds of 41.5001 and 42.3772
  # and the longitude is within the bounds of -88.2959 and -87.316
  col_vals_between(latitude, left = 41.5001, right = 42.3772,) |> 
  col_vals_between(longitude, left = -88.2959, right = -87.316)


agent

```

If we look at the output of `agent`, it shows our validation plan, but
the action is yet to come when we **interrogate**.

```{r}
#| label: interrogate the inspections_filtered agent

agent |> interrogate()

```

Explore the validation report. Can you:

1.  Identify what fail percentage each validation had?
2.  Identify how many rows failed each validation?
3.  View the CSV extracts of failed data?

Change the parameters of your validations to trigger more failures just
to see the consequence.

## Task 2 - Add Action Levels

🔄 Task

Iterate on your agent created above to add action levels. Action levels
behave like tags. You can decide what threshold you want to put for
`notify`, `warn`, and `stop`. At a minimum, the tag will provide a
visual indicator of threshold exceedance in the validation table. You
can also use these tags post-interrogation to take actions.

The action levels can be set as an **integer**, representing the
threshold number of failing units, or a **fraction**, representing the
fraction of failing units.

Use
`actions = action_levels(warn_at = ____, stop_at = ____, notify_at = ____)`
to add action levels to one, some, or all of your validations and rerun
the interrogation to see the output. Some samples have been provided.

```{r}
#| label: validation of inspections_filtered with action levels

agent <- create_agent(inspections_filtered) |> 
  # verify license number is not NULL or NA
  col_vals_not_null(columns = license_number,
                    actions = action_levels(warn_at = 0.2, stop_at = 0.3)) |> 
  # verify license number is greater than 2000
  col_vals_gt(columns = license_number, 2000,
              actions = action_levels(warn_at = 0.005)) |> 
  # verify inspection date is valid
  col_vals_lte(columns = inspection_date, today(),
               label = "Is inspection date in the past?") |> 
  # Now add the following:
  # verify that address, latitude, and/or longitude are not null/NA
  # (hint: use `vars(x,y,z)` to apply the validation to multiple columns)
  col_vals_not_null(vars(address, latitude, longitude)) |> 
  # verify that the values in inspection ID are distinct 
  rows_distinct(vars(inspection_id), 
                label = "Is the Inspection ID unique?") |> 
  # verify the latitude is within the bounds of 41.5001 and 42.3772
  # and the longitude is within the bounds of -88.2959 and -87.316
  col_vals_between(latitude, left = 41.5001, right = 42.3772,) |> 
  col_vals_between(longitude, left = -88.2959, right = -87.316) |> 
  
  interrogate()

agent

```

## Task 3 - Remove failing data from the data set

🔄 Task

Pointblank has identified all of the rows of `inspections_filtered` that
passed and failed validation. Now remove those that failed so the data
that is passed downstream to our modeling step is squeaky clean.

Pointblank provides a number of [post-interrogation functions](#0) to
work with intel gathered from the validation. For this task, we will
"sunder" the data using `pointblank::get_sundered_data()`.

> **💡 sunder** /sun·der / ˈsən-dər / *verb* \| to split apart

```{r}
#| label: sunder data

# Passed data
inspections_validated <- get_sundered_data(agent = agent,
                                           type = "pass")

# Failed data
inspections_failed_validation <- get_sundered_data(agent = agent,
                                        type = "fail")

```

## Task 4 - Post-interrogation logicals

Pointblank interrogation provides multiple layers of information about
our data. We can take advantage of this with logical TRUE / FALSE
statements that drive downstream tasks or effects.

-   Use `pointblank::all_passed()` to determine if all validation steps
    passed

-   Use `pointblank::get_agent_x_list` to determine if any warnings were
    set

```{r}
#| label: All validations passed?

# Did all validations pass?
pointblank::all_passed(agent)


```

A broad all passed / failed for the entire validation plan might not
provide enough granularity for a downstream task. We can drill into more
details about each step of the validation and the results using the
agent "x_list".

First we will see what the x_list contains.

```{r}
#| label: get agent x list

xlist <- pointblank::get_agent_x_list(agent)

xlist

```

The output is like a gold mine! The resulting list includes the pass /
fail statistics (`$n_passed`, `$n_failed`, `$f_passed`, `$f_failed`) and
what we are after -- the validations with warnings. Let's take a look.

```{r}
#| label: Any warning flags set?

xlist$warn

```

Extracting these basic TRUE / FALSE values can be powerful for next
steps. We'll see how we can send conditional emails in the next section
of the workshop.
